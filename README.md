# RAG-Augmented LLM

This repository contains resources and evaluation notebooks for a Retrieval-Augmented Generation (RAG) pipeline using Large Language Models (LLMs), focusing on experimentation and benchmarking. Example notebooks utilize models such as Mistral-7B and Llama-3-1-8B for information retrieval, augmentation, and generation tasks.

## Project Overview

RAG-Augmented LLM combines advanced language models with external knowledge retrieval to produce more informed and context-rich responses.  
Key features include:
- Integration of retrieval and augmentation steps with LLMs
- Example workflows in Jupyter notebooks
- Evaluation scripts for benchmarking model performance

## Getting Started

### Prerequisites

- Python 3.8+
- Jupyter Notebook
- Required Python packages (see the notebook for details)

### Installation

Clone the repository:
```bash
git clone https://github.com/aparnavinayankozhipuram/Mistral-7B-Evaluation.git
cd Mistral-7B-Evaluation
```

Install dependencies:
```bash
pip install -r requirements.txt
```

### Usage

Open the notebook:
```
jupyter notebook Copy_of_Llama_3_1_8B_RAG_Retrieve,_Augment_and_Generate_results_1st_query_1st_iteration_Humannutrients.ipynb
```

Follow the instructions in the notebook to run the RAG pipeline and evaluate results.

## Repository Structure

- `Copy_of_Llama_3_1_8B_RAG_Retrieve,_Augment_and_Generate_results_1st_query_1st_iteration_Humannutrients.ipynb`: Example RAG workflow and evaluation.
- `requirements.txt`: Python dependencies.

## Contributing

Contributions are welcome! Please open an issue or submit a pull request for suggestions, bug fixes, or improvements.

## License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

## Acknowledgements

- [Mistral-7B](https://github.com/mistralai/Mistral-7B)
- [Llama-3](https://github.com/meta-llama/llama3)
- Other open-source contributors

## Contact

For questions or collaboration, reach out via [GitHub Issues](https://github.com/aparnavinayankozhipuram/Mistral-7B-Evaluation/issues).
